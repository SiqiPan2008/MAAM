\documentclass{article}
\usepackage{ctex}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{caption}
\RequirePackage{longtable,multirow,array}
\RequirePackage{booktabs}
\usepackage{booktabs}
\usepackage{multicol}
\usepackage{longtable}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage[style=ieee,sorting=nyt]{biblatex}
\assignrefcontextentries[]{*}
\addbibresource{References.bib}
\geometry{left=1in, right=1in, top=1in, bottom=1in}
\hypersetup{hidelinks}
\hypersetup{bookmarksnumbered=true,
	bookmarksopen=true,
	colorlinks=true,
	linkcolor=black,
	citecolor=blue,
	urlcolor=black}
\usepackage{tikz}
\usepackage{pgfplotstable}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\captionsetup{justification=centering}
\captionsetup[figure]{name={Fig.},labelsep=space,labelfont=bf}
\captionsetup[table]{name={Table},labelsep=space,labelfont=bf}
\CTEXoptions[today=old, contentsname=Contents]
\newcommand{\authyear}[1]{\citeauthor{#1} (\citeyear{#1})}
\setmainfont{Arial}

\newcommand{\toB}[1]{\color{blue}#1\color{black}}

\begin{document}
	\title{\vspace{-2.25cm} Multimodal Abnormity-Aware Model\\for Ocular Disease Diagnosis}
	\author{Siqi Pan}
	\date{}
	\maketitle
	
	\section*{Abstract}
	
	TEXT: abstract
	
	\pagebreak
	
	\section{Background}
		
		TEXT: Edit background
		
		Ocular diseases can be diagnosed through various methods, including using optical coherence tomography (OCT) and color fundus images. Ophthalmologists usually identify ocular abnormalities to deduce the disease.  Traditionally, the diagnosis primarily depends on the professional experience and knowledge of the ophthalmologists, which may result in high misdiagnosis rate and under-utilization of medical data.  With the widespread application of artificial intelligence (AI), deep learning (DL) has made great contributions in providing support to patients in remote areas by sharing expert knowledge \autocite{Ichhpujani_Thakur_2021}.  By leveraging DL, researchers have developed auxiliary diagnosis programs to help doctors in the process. Many studies use convolutional neural network (CNN) to analyze ocular images. Some commonly used CNNs are VGG, ResNet, and Inception \autocite{daich2023artificial}.  And for segmenting images and finding abnormalities, U-net is widely used \autocite{Ronneberger_Fischer_Brox_2015}. In training CNNs, most studies use transferred learning, which consists of three steps: learning, fine-tuning, and validation.
		
		Some studies directly predict the disease from OCT images.
		\authyear{li2019deep} used ResNet to analyze OCT images and distinguish between choroidal neovascularization (CNV), diabetic macular edema (DME), drusen, and normal eyes. In addition, they performed occlusion testing to find out the regions that are the most important in diagnosis \autocite{li2019deep}. 
		\authyear{yoo2021feasibility} used generative adversarial network (GAN) and Inception-v3 together with a few-shot dataset to investigate the feasibility of improving OCT diagnosis of rare ocular diseases \autocite{yoo2021feasibility}.  They cleverly handled the issues of training image shortage and data imbalance by creating ocular disease OCT images from healthy OCT images. \authyear{Kermany2018} conducts medical diagnosis and identifies treatable diseases by image-based deep learning.  They also provided a widely used database including more than one hundred thousand OCT labeled images for 3 diseases \autocite{Kermany2018}.
		
		Some other studies can identify ocular abnormalities from annotated OCT images.
		\authyear{camino2018deep} used DL to identify the region of preserved photoreceptors on \textit{en face} OCT in choroideremia and retinitis pigmentosa (RP) \autocite{camino2018deep}. 
		\authyear{srinivasan2014fully} detected DME and dry age-related macular degeneration (dry AMD) from OCT images by flattening the image and using support vector machine (SVM) to extract the thickness information of the retinal layers \autocite{srinivasan2014fully}. 
		\authyear{leandro2023oct} implemented VGG to identify up to 8 kinds of key abnormalities and hence detect multiple diseases by using central fovea cross-section OCT \autocite{leandro2023oct}.  \authyear{Fang_Wang2019} developed a novel lesion-aware CNN, called LACNN, to simulate the ophthalmologists' diagnosis that focuses on ocular abnormalities.  The LACNN is a U-net-like CNN which incorporates VGG16 as the baseline, and the result is impressive \autocite{Fang_Wang2019}.
		
		Other studies use fundus images to predict ocular diseases.
		\authyear{masumoto2019accuracy} trained deep CNN with ultrawide-field fundus images to make the CNN capable of diagnosing RP \autocite{masumoto2019accuracy}. 
		\authyear{chen2021artificial} uses color fundus photographs and multiple types of CNN (Inception V3, Inception Resnet V2, and Xception) to develop a method of early detection of RP \autocite{chen2021artificial}. 
		\authyear{li2022development} uses CNN to detect up to 12 fundus diseases based on colour fundus photography \autocite{li2022development}.  \authyear{Son2023} presented a novel architectural and algorithmic design to comprehensively identify 15 abnormalities and diagnose 8 major ocular diseases from macula-centered fundus images.  They defined a notion of counterfactual attribution ratio (CAR) to interpret the system's diagnostic reason and disclose the relationship between abnormalities and diseases \autocite{Son2023}.
		
		In recent years, more and more DL systems began to use multi-modal information to predict ocular diseases.  For automated detection system, retrieving features from both OCT images and fundus images can effectively keep the diagnosis away from bias and incompleteness.  It is not always necessary to yield a better automated diagnosis result, but it does help ophthalmologist to make more accurate and holistic clinical decisions.  For instance, \authyear{liu2023prediction} combined OCT and fundus images to evaluate visual impairment in RP in terms of best-corrected visual acuity(BCVA) \autocite{liu2023prediction}.  \authyear{Xu2021} leveraged a bi-modal CNN to diagnose AMD and polypoidal choroidal vasculopathy (PCV), where the architecture uses fundus and OCT images as input for transferred learning CNN and concatenates the retrieved features to classify 3 diseases including dry AMD, wet AMD and PCV \autocite{Xu2021}.  And \author{Andrearczyk2018} ingeniously combined medical images and biomedical textual information to discriminate different diseases, which is a novel method for the usage of multi-modal application \autocite{Andrearczyk2018}.
		
		The key technical problem of multi-modal diagnosis is how to fuse the results from multifarious sources.  There are three types of fusion, namely early, late, and hybrid fusion.  Deciding on the optimal type of fusion is part of the exploratory process in the application of DL methods \autocite{Ichhpujani_Thakur_2021}.
		
		
	
	\section{Overview}
		
		We develop a multimodal abnormity-aware model to aid doctors in diagnosing ocular diseases. It is a multimodal model and considers both OCT and color fundus image inputs. In addition, tt simulates the decision-making process of doctors when they examine patients with ocular diseases, i.e., first identifying the abnormities, and then deducing the disease. Thus, it partly opens up the ``black box'' of DL and presents more interpretable conclusions. 
		
		\begin{figure}[htbp]
			\centering
			\includegraphics[width=\linewidth]{Figs/Temp.png}
			\caption{Model Overview}
			\vspace{0.3cm}
			\label{fig:3_parts}
		\end{figure}
		
		The structure of the model is shown in Fig.~\ref{fig:3_parts}. The model constitutes of 2 parts: the Abnormity Models and the Diagnosis Model. 
		
		The Abnormity Models consists of the OCT Model and the Fundus Model, which identify OCT and Fundus abnormities, respectively. Both of the Abnormity Models are CNNs with modified final FC layers. All CNNs that are used for classification tasks can be used. In this study, we consider ResNet152, ResNet50, ResNet18 and VGG16, and choose the best CNN for both Abnormity Models. The final FC layers are modified so that the size of their output vectors is equal to the number of OCT or Fundus abnormities. We also add a softmax layer after it. After an image is inputted into one of the Abnormity Models, the model returns a probability vector containing the probabilities of different abnormities.
		
		The Diagnosis Model consists of two stages: the Abnormity Number Stage (Stage D1) and the Disease Probability Stage (Stage D2). In Stage D1, there is a submodel for each of the diseases. Each submodel takes input from the OCT and Fundus Models, passes the input through a FC layer and a softmax layer, and determines how many abnormities that are related to the specific disease (as in Fig.~\ref{fig:criteria}) are present in an image. Then, in Stage D2, the output of all the submodels in Stage D1 passes through a FC layer and a softmax layer, and returns a disease probability vector.
		
		\begin{figure}[htbp]
			\centering
			\includegraphics[width=\linewidth]{Figs/Temp.png}
			\caption{OCT and Fundus abnormities}
			\vspace{0.3cm}
			\label{fig:abnormities}
		\end{figure}
		
		Abnormities are symptoms that can be directly observed in the images. The model is trained to identify 12 OCT abnormities (including normal) and 9 Fundus abnormities (including normal), as shown in Fig.~\ref{fig:abnormities}.
		
		\begin{figure}[htbp]
			\centering
			\includegraphics[width=\linewidth]{Figs/Temp.png}
			\caption{Abnormity-to-disease conversion criteria}
			\vspace{0.3cm}
			\label{fig:criteria}
		\end{figure}
		
		Most of the data we acquire are only labeled with abnormities. Therefore, we compose the following abnormity-to-disease conversion criteria and use these criteria to generate data for training the Diagnosis Model (see Fig.~\ref{fig:criteria}). 
		
		\begin{figure}[htbp]
			\centering
			\includegraphics[width=\linewidth]{Figs/Temp.png}
			\caption{Fusion}
			\vspace{0.3cm}
			\label{fig:fusion}
		\end{figure}
		
		Fig.~\ref{fig:fusion} shows how the different parts of the ODADS are connected.
		
		When multiple OCT and Fundus images are inputted, they are passed through the Abnormity Models, resulting in multiple OCT and Fundus probability vectors. For each OCT abnormity, we choose the maximum probability  from the OCT probability vectors. Thus, we can get a final OCT probability vector with all the maximum probabilities. We do this for Fundus as well, and then concatenate the final OCT and Fundus vectors as an input to the Diagnosis Model.
		
		Stage D1 then takes the input and generates multiple abnormity number vectors. All these vectors are concatenated and inputted into Stage D2, which finally yields the probability vector of diseases.
		
		The results are then given to a user interface and shown to the user.
		
		
	\section{Abnormity Models}
	
		\subsection{Data Preparation}
			
			\begin{figure}[htbp]
				\centering
				\includegraphics[width=\linewidth]{Figs/Temp.png}
				\caption{Data preparation for abnormity models}
				\vspace{0.3cm}
				\label{fig:A_data_prep}
			\end{figure}
			
			{
				\fontsize{9}{12}\selectfont
				1. Normal Disease Database
				2. OpenICPSR
				3. Few-shot
				4. Google Image
				
				
				\begin{longtable}{lp{3.8in}}
					\caption{OCT and Fundus image sources}
					\label{tb:source}
					\toprule
					Abnormality&Description\\
					\midrule
					
					a & b\\
					
					\bottomrule
				\end{longtable}
			}
			
			Table: Data source for OCT and Fundus
				numbered list of sources
				columns for source number, final column = total number of imgs
				rows for abnormities
			
			TEXT: CycleGAN
				Table: selection rates
				selection criteria
				Why I did not GAN Fundus
				
			TEXT: transforms for OCT
				for train: copy, flip, randomcomb1
				for test: copy, flip, randomcomb2 -> explain truthfulness
				explain differences between train and test, OCT and fundus

			Table: all data source
			
		\subsection{Training}
			
			TEXT: intro to five-fold train/valid (reason for using this?)
			
			TEXT: starting point of fine-tuning
			prevent overfitting
			
			TEXT: crossentropyloss, ADAM optimizer with LR 1e-3, batchSize 16, number of epochs...
			conda, PyTorch;
			desktop computer with Intel$^®$ Xeon$^®$ Platinum 8352V Processor, 256G of RAM and 2 NVIDIA GPU (GeForce RTX 4090) with 48 VRAM
			
			\begin{figure}[htbp]
				\centering
				\includegraphics[width=\linewidth]{Figs/abnormity_OCT_loss_and_acc.pdf}
				\caption{AO train}
				\vspace{0.3cm}
				\label{fig:AO_train}
			\end{figure}
			
			\begin{figure}[htbp]
				\centering
				\includegraphics[width=\linewidth]{Figs/abnormity_Fundus_loss_and_acc.pdf}
				\caption{AF train}
				\vspace{0.3cm}
				\label{fig:AF_train}
			\end{figure}
			
			Graph bar chart for comparison? 
			
			TEXT: comments
			
		\subsection{Results}
			
			TEXT: accuracy; explain top-probs method
			
			
			
			\begin{table}[htbp]
				\centering
				\caption{OCT Test}
				\label{tb:OCT_test}
				\pgfplotstabletypeset[
					multicolumn names,
					col sep=comma,
					columns = {Abnormity, Precision, Sensitivity, Specificity, FOne, AUC},
					columns/Abnormity/.style={string type, column name=Abnormities},
					columns/Precision/.style={string type, column name=Precision},
					columns/Sensitivity/.style={string type, column name=Sensitivity},
					columns/Specificity/.style={string type, column name=Specificity},
					columns/FOne/.style={string type, column name={F1 Score}},
					columns/AUC/.style={string type, column name=AUC},
					every head row/.style={before row=\toprule, after row=\midrule},
					every last row/.style={ after row=\bottomrule}
				]{Tables/abnormity_o_test.csv}
			\end{table}
			
			\begin{table}[htbp]
				\centering
				\caption{Fundus Test}
				\label{tb:Fundus_test}
				\pgfplotstabletypeset[
				multicolumn names,
				col sep=comma,
				columns = {Abnormity, Precision, Sensitivity, Specificity, FOne, AUC},
				columns/Abnormity/.style={string type, column name=Abnormities},
				columns/Precision/.style={string type, column name=Precision},
				columns/Sensitivity/.style={string type, column name=Sensitivity},
				columns/Specificity/.style={string type, column name=Specificity},
				columns/FOne/.style={string type, column name={F1 Score}},
				columns/AUC/.style={string type, column name=AUC},
				every head row/.style={before row=\toprule, after row=\midrule},
				every last row/.style={after row=\bottomrule}
				]{Tables/abnormity_f_test.csv}
			\end{table}
			
			\begin{figure}[htbp]
				\centering
				\includegraphics[width=0.8\linewidth]{Figs/abnormity_confusion_matrix.pdf}
				\caption{A Conf Mat}
				\vspace{0.3cm}
				\label{fig:A_conf_mat}
			\end{figure}
			
			TEXT: analyze which abnormities are commonly confused, and the effect on the numerical results
			
			\begin{figure}[htbp]
				\centering
				\includegraphics[width=\linewidth]{Figs/abnormity_tSNE.pdf}
				\caption{A ROC}
				\vspace{0.3cm}
				\label{fig:A_tSNE}
			\end{figure}
			
			TEXT: which abnormities are "close"
			
			\begin{figure}[htbp]
				\centering
				\includegraphics[width=\linewidth]{Figs/abnormity_ROC.pdf}
				\caption{A ROC}
				\vspace{0.3cm}
				\label{fig:A_ROC}
			\end{figure}
			
			TEXT: comparison to other studies
				
			\begin{figure}[htbp]
				\centering
				\includegraphics[width=\linewidth]{Figs/abnormity_gradCAM.png}
				\caption{GradCAM}
				\vspace{0.3cm}
				\label{fig:gradCAM}
			\end{figure}
			\begin{figure}[htbp]
				\centering
				\includegraphics[width=\linewidth]{Figs/abnormity_gradCAM_multiple_abnormities.png}
				\caption{GradCAM with multiple abnormities}
				\vspace{0.3cm}
				\label{fig:gradCAM_multi_abnormity}
			\end{figure}
		
	\section{Diagnosis Model}
	
		\subsection{Data Preparation}
		
			TEXT: how to choose data (with an example)
			how to find level (number of traits = level for the disease as label during training)
			
		
		\subsection{Training}
			
			TEXT: hyperparameters, software, hardware
			
			TEXT: comments
				
				
		\subsection{Results}
			
			TEXT: D1 output - calculate expected grade. in order to compare, divide by total number of traits for this disease so that normalized grade falls in [0, 1]. 
			used for checking number of abnormities associated to the disease
			
			TEXT: top-probs method
			
			\begin{table}[htbp]
				\centering
				\caption{Diagnosis Test}
				\label{tb:diagnosis_test}
				\pgfplotstabletypeset[
				multicolumn names,
				col sep=comma,
				columns = {Abnormity, Precision, Sensitivity, Specificity, FOne, AUC},
				columns/Abnormity/.style={string type, column name=Abnormities},
				columns/Precision/.style={string type, column name=Precision},
				columns/Sensitivity/.style={string type, column name=Sensitivity},
				columns/Specificity/.style={string type, column name=Specificity},
				columns/FOne/.style={string type, column name={F1 Score}},
				columns/AUC/.style={string type, column name=AUC},
				every head row/.style={before row=\toprule, after row=\midrule},
				every last row/.style={ after row=\bottomrule}
				]{Tables/diagnosis2.csv}
			\end{table}
			
			\begin{figure}[htbp]
				\centering
				\includegraphics[width=\linewidth]{Figs/diagnosis1_acc_barchart.pdf}
				\caption{D1 Acc Bar}
				\vspace{0.3cm}
				\label{fig:D1_acc_bar}
			\end{figure}
			
			\begin{figure}[htbp]
				\centering
				\includegraphics[width=\linewidth]{Figs/diagnosis1_confusion_matrix.pdf}
				\caption{D1 Conf Mat}
				\vspace{0.3cm}
				\label{fig:D1_conf_mat}
			\end{figure}
			TEXT: comments
			
			\begin{figure}[htbp]
				\centering
				\includegraphics[width=\linewidth]{Figs/diagnosis2_confusion_matrix.pdf}
				\caption{D2 Conf Mat}
				\vspace{0.3cm}
				\label{fig:D2_conf_mat}
			\end{figure}
			\begin{figure}[htbp]
				\centering
				\includegraphics[width=\linewidth]{Figs/diagnosis2_tSNE.pdf}
				\caption{D2 tSNE}
				\vspace{0.3cm}
				\label{fig:D2_tSNE}
			\end{figure}
			TEXT: comments
			
			\begin{figure}[htbp]
				\centering
				\includegraphics[width=\linewidth]{Figs/diagnosis2_ROC.pdf}
				\caption{D2 ROC}
				\vspace{0.3cm}
				\label{fig:D2_ROC}
			\end{figure}
			TEXT: comparison and comments
	
	\section{Discussion}
		
		TEXT: Do two models increase accuracy? How?
		
		TEXT: Comparison to other studies
		
		TEXT: Strengths and weaknesses
		how to improve
		
	\section{Conclusion}
	
		TEXT: conclusion

	\phantomsection
	\addcontentsline{toc}{section}{References}
	\newrefcontext[sorting=nyt]
	\printbibliography
	
	\pagebreak
	\section*{Appendix}
	
	List: Google Image source links
	
	Table: abnormities with description (edit the two tables below)
	
	{
		\fontsize{9}{12}\selectfont
		\begin{longtable}{lp{3.8in}}
			\caption{OCT Abnormities}
			\label{tb:oct-abnormites}\\
			\toprule
			Abnormality&Description\\
			\midrule
			
			\multicolumn{1}{l}{Central serous chorioretinopathy (CSC)}
			& \multicolumn{1}{l}{The accumulation of fluid underneath the retina.}\\
			
			\multicolumn{1}{l}{Epiretinal membrane (ERM)}
			& A thin layer of fibrous tissue forms on the surface of the retina, particularly the macula.\\
			
			\multicolumn{1}{l}{Macular hole (MH)}
			& Disruption or discontinuity in the normal retinal layers surrounding the macular hole.\\
			
			\multicolumn{1}{l}{Stargardt disease}
			& Thinning and atrophy of the retina. Disruption of photoreceptor layers. Presence of subretinal deposits.\\
			
			\multicolumn{1}{l}{Retinitis pigmentosa (RP)}
			& Thinning of the Retinal Layers. Disruption of Photoreceptor Layers. Attenuation of Retinal Vasculature.\\
			
			\multicolumn{1}{l}{Macular telangiectasia (Mactel)}
			& Abnormalities in the macular blood vessels, leading to changes in the macular structure and function\\
			
			\multicolumn{1}{l}{Diabetic macular edema (DME)}
			& The accumulation of fluid in the macula. \\
			
			\multicolumn{1}{l}{Choroidal neovascularization}
			& The abnormal growth of new blood vessels in the choroid layer.\\
			
			\multicolumn{1}{l}{Subretinal fluid}
			&  The accumulation of fluid between the neurosensory retina and the retinal pigment epithelium (RPE)\\
			
			\multicolumn{1}{l}{Intraretinal fluid}
			& The accumulation of fluid within the layers of the retina.\\
			
			\multicolumn{1}{l}{Drusen}
			& Small deposits of extracellular material that accumulate beneath the retinal pigment epithelium (RPE) or between the RPE and the photoreceptor layer in the macular region of the retina.\\
			
			\bottomrule
		\end{longtable}
	}
	
	{
		\fontsize{9}{12}\selectfont
		\begin{longtable}{lp{3.8in}}
			\caption{Fundus Abnormalities}
			\label{tb:fundus-ab}\\
			\toprule
			Abnormality&Description\\
			\midrule
			
			\multicolumn{1}{l}{Retinitis pigmentosa (RP)}
			& Description of RP\\
			
			\multicolumn{1}{l}{Microaneurysm}
			& Description of microaneurysm\\
			
			\multicolumn{1}{l}{Macular hole (MH)} & Full-thickness macular hole showing a surrounding cuff of subretinal fluid.\\
			
			\multicolumn{1}{l}{Hard exudate} & Yellow or Yellow-White Deposits.  Hard Borders.  Distribution.  Clustering Around Blood Vessels\\
			
			\multicolumn{1}{l}{Hemorrhage} & Small dot-like to larger blot.  Fresh hemorrhages typically appear bright red or deep red in color, indicating the presence of oxygenated blood. Over time, as the blood undergoes degradation and clotting, the hemorrhage may change color to darker red, orange, or yellowish hues.\\
			
			\multicolumn{1}{l}{Cotton wool patch / soft exudate} & White or off-white lesions.  Irregular shapes and margins.\\
			
			\multicolumn{1}{l}{Vascular abnormality} & Retinal Vessel Tortuosity.  Retinal Vessel Caliber Changes.  \\
			
			\multicolumn{1}{l}{Drusen} & Small, round or oval-shaped yellow or white deposits.\\
			
			\bottomrule
		\end{longtable}
	}
	
	
	\begin{figure}[htbp]
		\centering
		\includegraphics[width=\linewidth]{Figs/Temp.png}
		\caption{Result Page}
		\vspace{0.3cm}
		\label{fig:result_page}
	\end{figure}
	
	TEXT: APP/website description
	
	Link: GitHub repo
	
\end{document}